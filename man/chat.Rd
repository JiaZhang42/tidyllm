% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/llm_verbs.R
\name{chat}
\alias{chat}
\title{Chat with a Language Model}
\usage{
chat(.llm, .provider = getOption("tidyllm_chat_default"))
}
\arguments{
\item{.llm}{An \code{LLMMessage} object containing the message or conversation history to send to the language model.}

\item{.provider}{A function or function call specifying the language model provider and any additional parameters.
This should be a call to a provider function like \code{openai()}, \code{claude()}, etc.
You can also set a default provider function via the \code{tidyllm_chat_default} option.}
}
\value{
An \code{LLMMessage}  object containing the response from the language model.
}
\description{
The \code{chat()} function allows you to send a message to a language model via a specified provider.
It routes the \code{LLMMessage} object to the appropriate provider-specific chat function.
}
\examples{
\dontrun{
llm_message("Hello World") |>
   chat(openai(.model = "gpt-4o"))
}
}
