% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tidyllm.R
\name{groq}
\alias{groq}
\title{Call the Groq API to interact with fast opensource models on Groq}
\usage{
groq(
  .llm,
  .model = "mixtral-8x7b-32768",
  .max_tokens = 1024,
  .temperature = NULL,
  .top_p = NULL,
  .frequency_penalty = NULL,
  .presence_penalty = NULL,
  .api_url = "https://api.groq.com/openai/v1/chat/completions",
  .timeout = 60
)
}
\arguments{
\item{.llm}{An existing LLMMessage object or an initial text prompt.}

\item{.model}{The model identifier (default: "gpt-4").}

\item{.max_tokens}{The maximum number of tokens to generate (default: 1024).}

\item{.temperature}{Control for randomness in response generation (optional).}

\item{.top_p}{Nucleus sampling parameter (optional).}

\item{.api_url}{Base URL for the API (default: "https://api.anthropic.com/v1/messages").}

\item{.timeout}{Request timeout in seconds (default: 60).}

\item{.top_k}{Top k sampling parameter (optional).}

\item{.system}{Additional system parameters (optional).}

\item{.metadata}{Additional metadata for the request (optional).}

\item{.stop_sequences}{Sequences that stop generation (optional).}

\item{.tools}{Additional tools used by the model (optional).}
}
\value{
Returns an updated LLMMessage object.
}
\description{
Call the Groq API to interact with fast opensource models on Groq
}
