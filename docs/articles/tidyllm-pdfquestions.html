<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Structured Question Answering from PDFs • tidyllm</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.4.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Structured Question Answering from PDFs">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">tidyllm</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.8</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../articles/tidyllm.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/tidyllm_classifiers.html">Classifying texts with tidyllm</a></li>
    <li><a class="dropdown-item" href="../articles/tidyllm-pdfquestions.html">Structured Question Answering from PDFs</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/edubruell/tidyllm/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Structured Question Answering from PDFs</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/edubruell/tidyllm/blob/HEAD/vignettes/articles/tidyllm-pdfquestions.Rmd" class="external-link"><code>vignettes/articles/tidyllm-pdfquestions.Rmd</code></a></small>
      <div class="d-none name"><code>tidyllm-pdfquestions.Rmd</code></div>
    </div>

    
    
<p>Navigating through a large collection of academic papers can be
time-consuming, especially when you’re trying to extract specific
insights or determine the relevance of each document to your research.
With <strong>tidyllm</strong>, you can streamline this process by
automating the extraction of structured answers directly from PDF
documents using large language models.</p>
<p>Imagine you have a folder of papers on the economic effects of
generative AI, and you need to assess how each paper is related to your
own research interests. This article will guide you through setting up a
workflow that processes the first few pages of each paper, asks an AI
model targeted questions, and returns the answers in a structured JSON
format — perfect for converting into a table for easy review and
analysis.</p>
<div class="section level2">
<h2 id="what-is-json-and-json-mode">What is JSON and JSON Mode?<a class="anchor" aria-label="anchor" href="#what-is-json-and-json-mode"></a>
</h2>
<p><strong>JSON</strong> (<a href="https://de.wikipedia.org/wiki/JavaScript_Object_Notation" class="external-link">JavaScript
Object Notation</a>) is a lightweight, text-based format for
representing structured data. It’s commonly used for transmitting data
between a server and web application or between different parts of a
system. A JSON object consists of key-value pairs, making it ideal for
capturing structured data like the title of a paper, its authors, or
answers to specific research questions.</p>
<p>In <strong>tidyllm</strong>, we can use the ability of many large
language models to write their answers in JSON to ensure that the AI
model returns answers in a structured format directly into R. This is
particularly useful for automating processes, such as extracting
information from multiple documents, and allows for easy conversion into
tables or further data manipulation.</p>
</div>
<div class="section level2">
<h2 id="context-length">Context length<a class="anchor" aria-label="anchor" href="#context-length"></a>
</h2>
<p>When working with long documents such as research papers, reports, or
even entire books, one challenge that arises is how much of the document
the model can handle at once. Large language models have a limitation
known as <strong>context</strong> length, which refers to the maximum
amount of text they can process in a single query. This is important
because if a document exceeds this limit, the model won’t be able to
process the entire content at once—leading to missing sections or
incomplete answers.</p>
<p>In most models, the context length is measured in tokens (the basic
units of text). For example, the maximum context length of many smaller
models is 8192 tokens which typically covers about 30-35 pages of text.
This means that for longer documents, like an academic paper that
exceeds this length, only the first portion of the document will be seen
by the model, potentially omitting key sections like the bibliography or
appendices, where important citations or results may reside.</p>
<p>To mitigate this, a common approach is to limit the number of pages
sent to the model for processing. For example, in this workflow, we
restrict the input to the first 35 pages, which typically includes the
abstract, introduction, methodology, results, and discussion—sections
that are most relevant for summarizing the paper. While this approach
ensures the model can process the core content of most academic papers,
it does mean that information typically found later in the document
could be missed.</p>
<p>Alternatively, for very large documents, you could split them into
smaller chunks and process each chunk separately. This way, you can
cover the entire content without exceeding the model’s context window.
However, keep in mind that doing so might disrupt the flow of the text
and make it harder for the model to retain overall context across
chunks.</p>
</div>
<div class="section level2">
<h2 id="example-workflow">Example Workflow<a class="anchor" aria-label="anchor" href="#example-workflow"></a>
</h2>
<p>Imagine your folder looks something like this—many downloaded papers,
but no structure yet:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org" class="external-link">tidyverse</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/edubruell/tidyllm" class="external-link">tidyllm</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/list.files.html" class="external-link">dir</a></span><span class="op">(</span><span class="st">"aipapers"</span><span class="op">)</span></span>
<span><span class="co">#&gt; character(0)</span></span></code></pre></div>
<p>We can write a simple function that processes a document and passes
it to the model. For demonstration purposes, I only send the first 35
pages of the pdf to the model, even though gpt-4o can handle 128,000
tokens. This feature is primarily needed, when you have large reports or
whole books that are larger than a typical models context window.
Usually for papers 35 pages should provide the model with enough
information to reasonably answer some main summarisation queries. If you
want to upload the complete files though, as possible with larger
models, you just need to specify a file name in the <code>.pdf</code>
argument as a string variable.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pdf_summary</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">file</span>, <span class="va">document_prompt</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="va">summary</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/llm_message.html">llm_message</a></span><span class="op">(</span><span class="va">document_prompt</span>, </span>
<span>              .pdf <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>                filename <span class="op">=</span> <span class="va">file</span>,</span>
<span>                start_page <span class="op">=</span> <span class="fl">1</span>,</span>
<span>                end_page <span class="op">=</span> <span class="fl">35</span><span class="op">)</span> </span>
<span>              <span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="../reference/chatgpt.html">chatgpt</a></span><span class="op">(</span>.json<span class="op">=</span><span class="cn">TRUE</span>,.stream<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>    <span class="fu"><a href="../reference/last_reply.html">last_reply</a></span><span class="op">(</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="va">summary</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>In this example, we use <code><a href="../reference/chatgpt.html">chatgpt()</a></code> with the default
<code>gpt-4o</code> model to answer our questions. For a 35-page paper,
the API cost is approximately $0.08, making it affordable to process
multiple papers with different queries. See details about <a href="https://openai.com/api/pricing/" class="external-link">pricing</a> here. While you could
also try open-source local models, paid remote models like
<code>gpt-4o</code> typically handle longer documents much more
effectively. Smaller local models, such as <code>gemma2:9B</code> in
<code><a href="../reference/ollama.html">ollama()</a></code>, often struggle with such extensive content even
though their context window is large. To use them, you might need to
reduce the number of processed pages or simplify your queries.
Alternatively, larger local models like <code>llama3::70B</code> could
work, but they require significant hardware resources to run
effectively.</p>
<blockquote>
<p>⚠️ <strong>Note:</strong> When using paid remote models, it’s
important to consider data privacy and security, especially if you’re
processing sensitive documents, as uploading data to external servers
may introduce risks — local models provide more control in such
cases.</p>
</blockquote>
<p>By enabling <code>.json = TRUE</code>, we instruct the model to
return its response in JSON format. To effectively extract key
information from multiple academic papers, we also need a consistent way
to prompt the large language model. The prompt we use specifies the
details we want from each document, such as the title, authors, type of
paper, and answers to some specific questions. Here our example
questions cover the empirical methods, theoretical framework, main
point, and the paper’s key contribution. You can of course ask more
specific questions and can extract information that is even more
relevant for your use case. But this is a nice start. We also give the
model the exact schema we need for our answers in order to make it
easier to work with the results in R.</p>
<p>Here is the example output for a lengthy prompt for one paper:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">files</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="st">"aipapers/"</span>,<span class="fu"><a href="https://rdrr.io/r/base/list.files.html" class="external-link">dir</a></span><span class="op">(</span><span class="st">"aipapers"</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">example_output</span> <span class="op">&lt;-</span> <span class="fu">pdf_summary</span><span class="op">(</span><span class="va">files</span><span class="op">[</span><span class="fl">8</span><span class="op">]</span>,document_prompt <span class="op">=</span> <span class="st">'</span></span>
<span><span class="st">Please analyze this document and provide the following details:</span></span>
<span><span class="st">    1. Title: The full title of the paper.</span></span>
<span><span class="st">    2. Authors: List of all authors.</span></span>
<span><span class="st">    3. Suggested new filename: A filename for the document in the format "ReleaseYear_Author_etal_ShortTitle.pdf"</span></span>
<span><span class="st">    4. Type: Is this a (brief) policy report or a research paper? Answer with either "Policy" or "Research"</span></span>
<span><span class="st">    5. Answer these four  questions based on the document. Each answer should be roughly one 100 words long:</span></span>
<span><span class="st">        Q1. What empirical methods are used in this work?</span></span>
<span><span class="st">        Q2. What theoretical framework is applied or discussed?</span></span>
<span><span class="st">        Q3. What is the main point or argument presented?</span></span>
<span><span class="st">        Q4. What is the key contribution of this work?</span></span>
<span><span class="st">    6. Key citations: List the four most important references that the document uses in describing its own contribution.</span></span>
<span><span class="st">    </span></span>
<span><span class="st">Please  answers only with a json output in the following format:</span></span>
<span><span class="st"></span></span>
<span><span class="st">{</span></span>
<span><span class="st">  "title": "",</span></span>
<span><span class="st">  "authors": [],</span></span>
<span><span class="st">  "suggested_new_filename": "",</span></span>
<span><span class="st">  "type": "",</span></span>
<span><span class="st">  "questions": {</span></span>
<span><span class="st">    "empirical_methods": "",</span></span>
<span><span class="st">    "theory": "",</span></span>
<span><span class="st">    "main_point": "",</span></span>
<span><span class="st">    "contribution": ""</span></span>
<span><span class="st">  },</span></span>
<span><span class="st">  "key_citations": []</span></span>
<span><span class="st">}</span></span>
<span><span class="st">'</span><span class="op">)</span></span>
<span></span>
<span><span class="va">example_output</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt; $raw_response</span></span>
<span><span class="co">#&gt; [1] "{\n  \"title\": \"The Rapid Adoption of Generative AI\",\n  \"authors\": [\"Alexander Bick\", \"Adam Blandin\", \"David J. Deming\"],\n  \"suggested_new_filename\": \"2024_Bick_etal_RapidAdoptionGenerativeAI.pdf\",\n  \"type\": \"Research\",\n  \"questions\": {\n    \"empirical_methods\": \"The paper employs a nationally representative survey method, the Real-Time Population Survey (RPS), to collect data on generative AI usage among the U.S. population. The RPS methodology aligns with the structure of the Current Population Survey (CPS) and ensures representativeness by benchmarking against national employment and earnings statistics. The survey allows flexibility in adding and modifying questions, enabling tracking of generative AI usage over time. This empirical approach provides comprehensive data on the adoption rates and usage patterns of generative AI in the United States, allowing the authors to analyze trends and draw comparisons with historical technological adoption metrics like PCs and the internet.\",\n    \"theory\": \"The theoretical framework revolves around the concept of technology adoption and its economic impact. The paper discusses generative AI as a general-purpose technology (GPT) that can be used across various occupations and tasks. It leverages existing theories on the diffusion of innovations and the role of technology in economic growth and inequality. References to historical analyses of previous GPTs, like personal computers and the internet, provide a backdrop for understanding the implications of generative AI. The authors discuss the potential for generative AI to affect productivity and labor market dynamics, drawing comparisons with past technological shifts.\",\n    \"main_point\": \"The main argument of the paper is that the adoption of generative AI in the United States is occurring at a faster pace than previous technological advances, such as personal computers and the internet. The authors highlight the broad utilization of generative AI across different demographics and occupations. They present evidence showing high usage rates both at work and home, with significant implications for productivity and potentially influencing workplace inequalities. They suggest that, although its rapid adoption could transform economic activities and job tasks, generative AI may amplify existing disparities due to unequal access among demographics.\",\n    \"contribution\": \"The key contribution of this work is the provision of first-of-its-kind empirical data on the adoption and use of generative AI among a representative sample of the U.S. population. By detailing generative AI's higher adoption rates compared to past technologies, the study offers insights into current trends and potential future impacts on labor markets and productivity. Moreover, it sheds light on demographic and occupational patterns in AI usage, informing debates on inequality and economic transformation. The paper's unique survey-based approach serves as a valuable resource for policymakers, researchers, and stakeholders interested in understanding and maximizing the potential benefits of generative AI adoption.\"\n  },\n  \"key_citations\": [\n    \"Brynjolfsson, Li, and Raymond, 2023\",\n    \"Acemoglu, Autor, Hazell, and Restrepo, 2022\",\n    \"Autor, Levy, and Murnane, 2003\",\n    \"Comin and Hobijn, 2010\"\n  ]\n}"</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $parsed_content</span></span>
<span><span class="co">#&gt; $parsed_content$title</span></span>
<span><span class="co">#&gt; [1] "The Rapid Adoption of Generative AI"</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $parsed_content$authors</span></span>
<span><span class="co">#&gt; [1] "Alexander Bick"  "Adam Blandin"    "David J. Deming"</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $parsed_content$suggested_new_filename</span></span>
<span><span class="co">#&gt; [1] "2024_Bick_etal_RapidAdoptionGenerativeAI.pdf"</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $parsed_content$type</span></span>
<span><span class="co">#&gt; [1] "Research"</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $parsed_content$questions</span></span>
<span><span class="co">#&gt; $parsed_content$questions$empirical_methods</span></span>
<span><span class="co">#&gt; [1] "The paper employs a nationally representative survey method, the Real-Time Population Survey (RPS), to collect data on generative AI usage among the U.S. population. The RPS methodology aligns with the structure of the Current Population Survey (CPS) and ensures representativeness by benchmarking against national employment and earnings statistics. The survey allows flexibility in adding and modifying questions, enabling tracking of generative AI usage over time. This empirical approach provides comprehensive data on the adoption rates and usage patterns of generative AI in the United States, allowing the authors to analyze trends and draw comparisons with historical technological adoption metrics like PCs and the internet."</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $parsed_content$questions$theory</span></span>
<span><span class="co">#&gt; [1] "The theoretical framework revolves around the concept of technology adoption and its economic impact. The paper discusses generative AI as a general-purpose technology (GPT) that can be used across various occupations and tasks. It leverages existing theories on the diffusion of innovations and the role of technology in economic growth and inequality. References to historical analyses of previous GPTs, like personal computers and the internet, provide a backdrop for understanding the implications of generative AI. The authors discuss the potential for generative AI to affect productivity and labor market dynamics, drawing comparisons with past technological shifts."</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $parsed_content$questions$main_point</span></span>
<span><span class="co">#&gt; [1] "The main argument of the paper is that the adoption of generative AI in the United States is occurring at a faster pace than previous technological advances, such as personal computers and the internet. The authors highlight the broad utilization of generative AI across different demographics and occupations. They present evidence showing high usage rates both at work and home, with significant implications for productivity and potentially influencing workplace inequalities. They suggest that, although its rapid adoption could transform economic activities and job tasks, generative AI may amplify existing disparities due to unequal access among demographics."</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $parsed_content$questions$contribution</span></span>
<span><span class="co">#&gt; [1] "The key contribution of this work is the provision of first-of-its-kind empirical data on the adoption and use of generative AI among a representative sample of the U.S. population. By detailing generative AI's higher adoption rates compared to past technologies, the study offers insights into current trends and potential future impacts on labor markets and productivity. Moreover, it sheds light on demographic and occupational patterns in AI usage, informing debates on inequality and economic transformation. The paper's unique survey-based approach serves as a valuable resource for policymakers, researchers, and stakeholders interested in understanding and maximizing the potential benefits of generative AI adoption."</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $parsed_content$key_citations</span></span>
<span><span class="co">#&gt; [1] "Brynjolfsson, Li, and Raymond, 2023"        </span></span>
<span><span class="co">#&gt; [2] "Acemoglu, Autor, Hazell, and Restrepo, 2022"</span></span>
<span><span class="co">#&gt; [3] "Autor, Levy, and Murnane, 2003"             </span></span>
<span><span class="co">#&gt; [4] "Comin and Hobijn, 2010"                     </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $is_parsed</span></span>
<span><span class="co">#&gt; [1] TRUE</span></span></code></pre>
<p>The output of the function seems quite daunting. But it is very close
to our prompt, where we specified a schema. It is structured into three
key components: <code>parsed_content</code>, <code>raw_response</code>,
and <code>is_parsed</code>. This structure ensures that you always have
access to the model’s reply in both in its raw form and as structured R
list:</p>
<ul>
<li>
<code>raw_response</code>: Even if the response is successfully
parsed, it’s useful to keep the original raw output from the model. This
field stores the unprocessed response as returned by the LLM, which can
be valuable for debugging or comparison purposes. Most models explicitly
check whether they return valid JSON. However, APIs without explicit
JSON support like Anthropic,often add sentences like <em>“Based on the
document, here is the requested information in JSON format:”</em> before
the actual json. In these cases it can not be parsed but is easy to fix
with the <code>raw_response</code>, <code>stringr</code> and
<code><a href="https://rdrr.io/pkg/jsonlite/man/fromJSON.html" class="external-link">jsonlite::fromJSON()</a></code>. However, printing out our raw
response in our example gives us a JSON in the structure we asked
for:</li>
</ul>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">example_output</span><span class="op">$</span><span class="va">raw_response</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; {</span></span>
<span><span class="co">#&gt;   "title": "The Rapid Adoption of Generative AI",</span></span>
<span><span class="co">#&gt;   "authors": ["Alexander Bick", "Adam Blandin", "David J. Deming"],</span></span>
<span><span class="co">#&gt;   "suggested_new_filename": "2024_Bick_etal_RapidAdoptionGenerativeAI.pdf",</span></span>
<span><span class="co">#&gt;   "type": "Research",</span></span>
<span><span class="co">#&gt;   "questions": {</span></span>
<span><span class="co">#&gt;     "empirical_methods": "The paper employs a nationally representative survey method, the Real-Time Population Survey (RPS), to collect data on generative AI usage among the U.S. population. The RPS methodology aligns with the structure of the Current Population Survey (CPS) and ensures representativeness by benchmarking against national employment and earnings statistics. The survey allows flexibility in adding and modifying questions, enabling tracking of generative AI usage over time. This empirical approach provides comprehensive data on the adoption rates and usage patterns of generative AI in the United States, allowing the authors to analyze trends and draw comparisons with historical technological adoption metrics like PCs and the internet.",</span></span>
<span><span class="co">#&gt;     "theory": "The theoretical framework revolves around the concept of technology adoption and its economic impact. The paper discusses generative AI as a general-purpose technology (GPT) that can be used across various occupations and tasks. It leverages existing theories on the diffusion of innovations and the role of technology in economic growth and inequality. References to historical analyses of previous GPTs, like personal computers and the internet, provide a backdrop for understanding the implications of generative AI. The authors discuss the potential for generative AI to affect productivity and labor market dynamics, drawing comparisons with past technological shifts.",</span></span>
<span><span class="co">#&gt;     "main_point": "The main argument of the paper is that the adoption of generative AI in the United States is occurring at a faster pace than previous technological advances, such as personal computers and the internet. The authors highlight the broad utilization of generative AI across different demographics and occupations. They present evidence showing high usage rates both at work and home, with significant implications for productivity and potentially influencing workplace inequalities. They suggest that, although its rapid adoption could transform economic activities and job tasks, generative AI may amplify existing disparities due to unequal access among demographics.",</span></span>
<span><span class="co">#&gt;     "contribution": "The key contribution of this work is the provision of first-of-its-kind empirical data on the adoption and use of generative AI among a representative sample of the U.S. population. By detailing generative AI's higher adoption rates compared to past technologies, the study offers insights into current trends and potential future impacts on labor markets and productivity. Moreover, it sheds light on demographic and occupational patterns in AI usage, informing debates on inequality and economic transformation. The paper's unique survey-based approach serves as a valuable resource for policymakers, researchers, and stakeholders interested in understanding and maximizing the potential benefits of generative AI adoption."</span></span>
<span><span class="co">#&gt;   },</span></span>
<span><span class="co">#&gt;   "key_citations": [</span></span>
<span><span class="co">#&gt;     "Brynjolfsson, Li, and Raymond, 2023",</span></span>
<span><span class="co">#&gt;     "Acemoglu, Autor, Hazell, and Restrepo, 2022",</span></span>
<span><span class="co">#&gt;     "Autor, Levy, and Murnane, 2003",</span></span>
<span><span class="co">#&gt;     "Comin and Hobijn, 2010"</span></span>
<span><span class="co">#&gt;   ]</span></span>
<span><span class="co">#&gt; }</span></span></code></pre></div>
<ul>
<li>
<code>parsed_content</code>: This field contains the structured
response after it has been successfully parsed to a list in R. It allows
you to directly access the specific elements of the reply, such as the
title, authors, and answers to your questions, making it easy to
integrate these results into further analysis or to save them to a human
readable document. For example you can directly get the suggested file
name from the response:</li>
</ul>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">example_output</span><span class="op">$</span><span class="va">parsed_content</span><span class="op">$</span><span class="va">suggested_new_filename</span></span>
<span><span class="co">#&gt; [1] "2024_Bick_etal_RapidAdoptionGenerativeAI.pdf"</span></span></code></pre></div>
<ul>
<li>
<code>is_parsed</code>: This is a logical flag indicating whether
the parsing was successful. If <code>TRUE</code>, it means that the
<code>parsed_content</code> is available and the output conforms to the
expected JSON structure. If <code>FALSE</code>, no parsed_content is
returned, and you can rely on the <code>raw_response</code> for
inspection or further manual handling.</li>
</ul>
<p>We can now run our function to generate this kind of response for all
papers in our folder:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pdf_responses</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html" class="external-link">map</a></span><span class="op">(</span><span class="va">files</span>,<span class="va">pdf_summary</span><span class="op">)</span></span></code></pre></div>
<p>Let’s look which files were successfully parsed:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pdf_responses</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html" class="external-link">map_lgl</a></span><span class="op">(</span><span class="st">"is_parsed"</span><span class="op">)</span> </span>
<span><span class="co">#&gt;  [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE</span></span>
<span><span class="co">#&gt; [16] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE</span></span></code></pre></div>
<p>Luckily, all of them did parse successfully. Now we can proceed with
getting the structured output from each response and saving it into an
easily readable format. For example we could have the name, all author
names,the paper type and the answers to our questions together in a row
of a tibble for each model output:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">table1</span> <span class="op">&lt;-</span> <span class="va">pdf_responses</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html" class="external-link">map</a></span><span class="op">(</span><span class="st">"parsed_content"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://purrr.tidyverse.org/reference/map_dfr.html" class="external-link">map_dfr</a></span><span class="op">(</span><span class="op">~</span><span class="op">{</span></span>
<span>    <span class="co">#Collapse authors into a single string</span></span>
<span>    <span class="va">base_info</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html" class="external-link">tibble</a></span><span class="op">(</span></span>
<span>      authors <span class="op">=</span> <span class="fu"><a href="https://stringr.tidyverse.org/reference/str_c.html" class="external-link">str_c</a></span><span class="op">(</span><span class="va">.x</span><span class="op">$</span><span class="va">authors</span>, collapse <span class="op">=</span> <span class="st">"; "</span><span class="op">)</span>,</span>
<span>      title   <span class="op">=</span> <span class="va">.x</span><span class="op">$</span><span class="va">title</span>,</span>
<span>      type    <span class="op">=</span> <span class="va">.x</span><span class="op">$</span><span class="va">type</span></span>
<span>    <span class="op">)</span> </span>
<span>    </span>
<span>    <span class="va">answers</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html" class="external-link">tibble</a></span><span class="op">(</span></span>
<span>     main_point   <span class="op">=</span> <span class="va">.x</span><span class="op">$</span><span class="va">questions</span><span class="op">$</span><span class="va">main_point</span>,</span>
<span>     contribution <span class="op">=</span><span class="va">.x</span><span class="op">$</span><span class="va">questions</span><span class="op">$</span><span class="va">contribution</span>,</span>
<span>     theory       <span class="op">=</span> <span class="va">.x</span><span class="op">$</span><span class="va">questions</span><span class="op">$</span><span class="va">theory</span>,</span>
<span>     methods      <span class="op">=</span> <span class="va">.x</span><span class="op">$</span><span class="va">questions</span><span class="op">$</span><span class="va">empirical_methods</span></span>
<span>    <span class="op">)</span></span>
<span>    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/bind_cols.html" class="external-link">bind_cols</a></span><span class="op">(</span><span class="va">base_info</span>,<span class="va">answers</span><span class="op">)</span></span>
<span>  <span class="op">}</span><span class="op">)</span></span>
<span></span>
<span><span class="va">table1</span> </span>
<span><span class="co">#&gt; <span style="color: #949494;"># A tibble: 23 × 7</span></span></span>
<span><span class="co">#&gt;    authors                    title type  main_point contribution theory methods</span></span>
<span><span class="co">#&gt;    <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>                      <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span> <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span> <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>      <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>        <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>  </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 1</span> John J. Horton             Larg… Rese… The main … The key con… The t… The pa…</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 2</span> Sida Peng; Eirini Kalliam… The … Rese… The main … The key con… The t… The em…</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 3</span> Tyna Eloundou; Sam Mannin… GPTs… Rese… The main … The key con… The t… The pa…</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 4</span> Philipp Lergetporer; Kath… Auto… Rese… The prima… The paper's… The t… The wo…</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 5</span> Andrew Green               Arti… Rese… The main … This work's… The t… The do…</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 6</span> Andrew Caplin; David J. D… The … Rese… The main … This work's… The t… The em…</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 7</span> Daron Acemoglu; Pascual R… Auto… Rese… The main … The key con… The t… The au…</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 8</span> Alexander Bick; Adam Blan… The … Rese… The main … The key con… The t… The em…</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 9</span> David Deming; Christopher… Tech… Poli… The main … The key con… The t… The pa…</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">10</span> Melanie Arntz; Sebastian … The … Rese… The main … The key con… The p… The au…</span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># ℹ 13 more rows</span></span></span></code></pre></div>
<p>We can then save these summaries to an excel table that we can format
manually for better readability:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">table1</span> <span class="op">|&gt;</span> <span class="fu">writexl</span><span class="fu">::</span><span class="fu"><a href="https://docs.ropensci.org/writexl/reference/write_xlsx.html" class="external-link">write_xlsx</a></span><span class="op">(</span><span class="st">"papers_summaries.xlsx"</span><span class="op">)</span></span></code></pre></div>
<p>Similarly we can extract the key references and add them to a
separate Excel file. A next step to work with our output, is to go
through parsed content and always pick out the
<code>key_citations</code> with map. But here in our example, we
encouter an error if we do that:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pdf_responses</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html" class="external-link">map</a></span><span class="op">(</span><span class="st">"parsed_content"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html" class="external-link">map</a></span><span class="op">(</span><span class="st">"key_citations"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://purrr.tidyverse.org/reference/map_dfr.html" class="external-link">map_dfr</a></span><span class="op">(</span><span class="op">~</span><span class="va">as_tibble</span><span class="op">)</span></span>
<span><span class="co">#&gt; <span style="color: #BBBB00; font-weight: bold;">Error</span><span style="font-weight: bold;"> in `dplyr::bind_rows()`:</span></span></span>
<span><span class="co">#&gt; <span style="color: #BBBB00;">!</span> Argument 1 must be a data frame or a named atomic vector.</span></span></code></pre></div>
<p>Looking into the cause you see a common problem with some JSON-based
workflows. You can see this problem in the raw responses of the second
paper that was parsed:</p>
<pre><code><span><span class="co">#&gt; {</span></span>
<span><span class="co">#&gt;   "title": ["The Impact of AI on Developer Productivity: Evidence from GitHub Copilot"],</span></span>
<span><span class="co">#&gt;   "authors": ["Sida Peng", "Eirini Kalliamvakou", "Peter Cihon", "Mert Demirer"],</span></span>
<span><span class="co">#&gt;   "suggested_new_filename": ["2023_Peng_etal_AI_Productivity.pdf"],</span></span>
<span><span class="co">#&gt;   "type": ["Research"],</span></span>
<span><span class="co">#&gt;   "questions": {</span></span>
<span><span class="co">#&gt;     "empirical_methods": [".. abbreviated .."],</span></span>
<span><span class="co">#&gt;     "theory": [".. abbreviated .."],</span></span>
<span><span class="co">#&gt;     "main_point": [".. abbreviated .."],</span></span>
<span><span class="co">#&gt;     "contribution": [".. abbreviated .."],</span></span>
<span><span class="co">#&gt;     "key_citations": ["Zhang et al., 2022", "Nguyen and Nadi, 2022", "Barke et al., 2022", "Mozannar et al., 2022"]</span></span>
<span><span class="co">#&gt;   }</span></span>
<span><span class="co">#&gt; }</span></span></code></pre>
<p><code>key_citations</code> was put under questions instead of as a
separate field. The model did not completely adhere to what we asked it
to produce. A quick fix for this problem is to check where
<code>key_citations</code> was put and to:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pdf_responses</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html" class="external-link">map</a></span><span class="op">(</span><span class="st">"parsed_content"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://purrr.tidyverse.org/reference/map_dfr.html" class="external-link">map_dfr</a></span><span class="op">(</span><span class="op">~</span><span class="op">{</span></span>
<span>    <span class="co"># Check if key_citations is nested under questions or at the top level</span></span>
<span>    <span class="va">citations</span> <span class="op">&lt;-</span> <span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NULL.html" class="external-link">is.null</a></span><span class="op">(</span><span class="va">.x</span><span class="op">$</span><span class="va">key_citations</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>      <span class="fu"><a href="https://tibble.tidyverse.org/reference/as_tibble.html" class="external-link">as_tibble</a></span><span class="op">(</span><span class="va">.x</span><span class="op">$</span><span class="va">key_citations</span><span class="op">)</span></span>
<span>    <span class="op">}</span> <span class="kw">else</span> <span class="kw">if</span> <span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NULL.html" class="external-link">is.null</a></span><span class="op">(</span><span class="va">.x</span><span class="op">$</span><span class="va">questions</span><span class="op">$</span><span class="va">key_citations</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>      <span class="fu"><a href="https://tibble.tidyverse.org/reference/as_tibble.html" class="external-link">as_tibble</a></span><span class="op">(</span><span class="va">.x</span><span class="op">$</span><span class="va">questions</span><span class="op">$</span><span class="va">key_citations</span><span class="op">)</span></span>
<span>    <span class="op">}</span></span>
<span>    <span class="va">citations</span></span>
<span>  <span class="op">}</span><span class="op">)</span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># A tibble: 91 × 1</span></span></span>
<span><span class="co">#&gt;    value                                                                        </span></span>
<span><span class="co">#&gt;    <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>                                                                        </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 1</span> Charness, G., &amp; Rabin, M. (2002). Understanding social preferences with simp…</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 2</span> Kahneman, D., Knetsch, J. L., &amp; Thaler, R. H. (1986). Fairness as a constrai…</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 3</span> Samuelson, W., &amp; Zeckhauser, R. (1988). Status quo bias in decision making.  </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 4</span> Aher, M., Arriaga, X., &amp; Kalai, A. (2022). Large language models as social a…</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 5</span> Zhang et al., 2022                                                           </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 6</span> Nguyen and Nadi, 2022                                                        </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 7</span> Barke et al., 2022                                                           </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 8</span> Mozannar et al., 2022                                                        </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 9</span> Brynjolfsson et al., 2018                                                    </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">10</span> Felten et al., 2018                                                          </span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># ℹ 81 more rows</span></span></span></code></pre></div>
<p>A better solution is to check at the start whether the model adheres
to the schema we requested. Many newer APIs, such as the most recent <a href="https://platform.openai.com/docs/guides/structured-outputs" class="external-link">OpenAI
API</a>, now offer the ability to pre-specify a valid output schema.
This means you can enforce strict formatting rules before the model
generates a response, reducing the need for post-processing corrections.
This functionality will be supported in future versions of
<strong>tidyllm</strong>, allowing for smoother integration of
structured outputs.</p>
<p>Another potential fix is to modify the prompt to ensure the model
outputs in a non-nested <em>JSON</em> format, which often simplifies
prompt adherence and downstream handling. In workflows like this, it’s
common to need several iterations to refine the structure of the output,
especially when working with complex queries. For example, in this case,
defining how citations should be formatted might also improve
consistency, since the <code>key_citation</code> field varies between
responses. Additionally, it may be beneficial to run a separate pass
just for citations, perhaps asking the model to output BibTeX keys for
the four most important references together with a reason why each
citation is important in the note-field of the bibtex.</p>
<p>But for now, we have the processing steps we wanted for answers and
citations and can proceed to the file names we got to structure our
folder:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html" class="external-link">tibble</a></span><span class="op">(</span>old_name  <span class="op">=</span> <span class="va">files</span>,</span>
<span>       new_name  <span class="op">=</span> <span class="va">pdf_responses</span> <span class="op">|&gt;</span></span>
<span>         <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html" class="external-link">map</a></span><span class="op">(</span><span class="st">"parsed_content"</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>         <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html" class="external-link">map_chr</a></span><span class="op">(</span><span class="st">"suggested_new_filename"</span><span class="op">)</span> </span>
<span>       <span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span></span>
<span>    success <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/files.html" class="external-link">file.rename</a></span><span class="op">(</span><span class="va">old_name</span>, <span class="fu"><a href="https://rdrr.io/r/base/file.path.html" class="external-link">file.path</a></span><span class="op">(</span><span class="st">"aipapers"</span>, <span class="va">new_name</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="outlook">Outlook<a class="anchor" aria-label="anchor" href="#outlook"></a>
</h2>
<p>This structured question-answering workflow not only streamlines the
extraction of key insights from academic papers, but can also be adapted
for other document-heavy tasks. Whether you’re working with reports,
policy documents, or news articles this approach can quickly help you
summarize and categorize information for further analysis. Additionally,
by refining prompts and leveraging schema validation, you can expand the
use of this workflow to handle various types of structured data, such as
extracting key insights from legal documents, patents, or even pictures
of historical documents— anywhere you need structured information from
unstructured text.</p>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Eduard Brüll.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
