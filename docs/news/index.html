<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Changelog â€¢ tidyllm</title><!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png"><link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png"><link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png"><link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png"><link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png"><link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png"><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.4.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Changelog"><meta property="og:image" content="https://edubruell.github.io/tidyllm/logo.png"></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">tidyllm</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.8</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="nav-item"><a class="nav-link" href="../articles/tidyllm.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles"><li><a class="dropdown-item" href="../articles/tidyllm_classifiers.html">Classifying Texts with tidyllm</a></li>
    <li><a class="dropdown-item" href="../articles/tidyllm-pdfquestions.html">Structured Question Answering from PDFs</a></li>
    <li><a class="dropdown-item" href="../articles/tidyllm-synthetic-data.html">Generate Synthetic Data with tidyllm</a></li>
  </ul></li>
<li class="active nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/edubruell/tidyllm/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-news">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Changelog</h1>
      <small>Source: <a href="https://github.com/edubruell/tidyllm/blob/HEAD/NEWS.md" class="external-link"><code>NEWS.md</code></a></small>
    </div>

    <div class="section level2">
<h2 class="pkg-version" data-toc-text="0.1.8" id="changelog-for-development-version-018">Changelog for Development Version 0.1.8<a class="anchor" aria-label="anchor" href="#changelog-for-development-version-018"></a></h2>
<p>Changes since the last CRAN Release 0.1.0</p>
<div class="section level3">
<h3 id="breaking-changes-compared-to-cran-release-0-1-8">Breaking Changes (Compared to CRAN Release 0.1.0)<a class="anchor" aria-label="anchor" href="#breaking-changes-compared-to-cran-release-0-1-8"></a></h3>
<ul><li>
<strong><code><a href="../reference/last_reply.html">last_reply()</a></code> Changes</strong>: The <code>.json</code> argument is no longer used, and JSON replies are automatically parsed. Use <code>.raw</code> for raw text.</li>
<li>
<strong>Groq Models</strong>: System prompts are no longer sent for Groq models, since many models on groq do not support them and all multimodal models on groq do not allow for them.</li>
</ul></div>
<div class="section level3">
<h3 id="new-features-0-1-8">New Features<a class="anchor" aria-label="anchor" href="#new-features-0-1-8"></a></h3>
<ul><li>
<p><strong>Embedding Models Support:</strong> Embedding model support for three APIs:</p>
<ul><li>Embedding functions process message histories and combines text from message content and media attachements for embedding models</li>
<li>
<code><a href="../reference/ollama_embedding.html">ollama_embedding()</a></code> to generate embeddings using the Ollama API.</li>
<li>
<code><a href="../reference/openai_embedding.html">openai_embedding()</a></code> to generate embeddings using the OpenAI API.</li>
<li>
<code><a href="../reference/mistral_embedding.html">mistral_embedding()</a></code> to generate embeddings using the Mistral API.</li>
</ul></li>
<li>
<p><strong>Message Retrieval Functions</strong>: Added functions to retrieve single messages from conversations:</p>
<ul><li>
<code><a href="../reference/last_user_message.html">last_user_message()</a></code> pulls the last message the user sent</li>
<li>
<code><a href="../reference/get_reply.html">get_reply()</a></code> gets the assistant reply at a given index of assistant messages</li>
<li>
<code><a href="../reference/get_user_message.html">get_user_message()</a></code> gets the user message at a given index of user messages</li>
</ul></li>
<li><p><strong>Updated <code><a href="../reference/last_reply.html">last_reply()</a></code></strong>: Now a wrapper around <code><a href="../reference/get_reply.html">get_reply()</a></code> for more consistent behavior.</p></li>
<li>
<p><strong>New Ollama functions</strong>:</p>
<ul><li>
<strong>Model Download:</strong> Introduced the <code><a href="../reference/ollama_download_model.html">ollama_download_model()</a></code> function to download models from the Ollama API. It supports a streaming mode that provides live progress bar updates on the download progress.</li>
</ul></li>
<li><p><strong>PDF Page Batch Processing</strong>: Introduced the <code><a href="../reference/pdf_page_batch.html">pdf_page_batch()</a></code> function, which processes PDF files page by page, extracting text and converting each page into an image and allows for a general prompt or page specific prompts. The function generates a list of <code>LLMMessage</code> objects that can each be sent to an API</p></li>
<li><p><strong>Support for the Mistral API</strong>: New <code><a href="../reference/mistral.html">mistral()</a></code> function to use Mistral Models on Le Platforme on servers hosted in the EU. With rate-limiting and streaming-support.</p></li>
<li><p><strong>PDF Page Support in <code><a href="../reference/llm_message.html">llm_message()</a></code>:</strong> The <code><a href="../reference/llm_message.html">llm_message()</a></code> function now supports specifying a range of pages in a PDF by passing a list with <code>filename</code>, <code>start_page</code>, and <code>end_page</code>. This allows users to extract and process specific pages of a PDF, as shown in the example below:</p></li>
</ul><div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span>  <span class="fu"><a href="../reference/llm_message.html">llm_message</a></span><span class="op">(</span></span>
<span>    .prompt <span class="op">=</span> <span class="st">"Please summarize pages 2 to 5 of the attached document."</span>,</span>
<span>    .pdf <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>      filename <span class="op">=</span> <span class="st">"path/to/your/document.pdf"</span>,</span>
<span>      start_page <span class="op">=</span> <span class="fl">2</span>,</span>
<span>      end_page <span class="op">=</span> <span class="fl">5</span></span>
<span>    <span class="op">)</span></span>
<span>  <span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="improvements-0-1-8">Improvements<a class="anchor" aria-label="anchor" href="#improvements-0-1-8"></a></h3>
</div>
<div class="section level3">
<h3 id="groq-support-for-vision-0-1-8">Groq support for vision<a class="anchor" aria-label="anchor" href="#groq-support-for-vision-0-1-8"></a></h3>
<p>The <code><a href="../reference/groq.html">groq()</a></code> function now supports images. Since more modern models on groq, especially the ones with multimodal abilities do not support system prompts, the system role is deleted from groq api calls.</p>
</div>
<div class="section level3">
<h3 id="json-mode-improvements-0-1-8">JSON Mode Improvements<a class="anchor" aria-label="anchor" href="#json-mode-improvements-0-1-8"></a></h3>
<p>Since version 0.1.1, JSON mode is now more widely supported across all API functions, allowing for structured outputs when APIs support them. The <code>.json</code> argument is now passed only to API functions, specifying how the API should respond, it is not needed anymore in <code><a href="../reference/last_reply.html">last_reply()</a></code>.</p>
<p>Additionally, the behavior of the reply functions has changed. They now automatically handle JSON replies by parsing them into structured data and falling back to raw text in case of errors. You can still force raw text replies even for JSON output using the <code>.raw</code> argument.</p>
</div>
<div class="section level3">
<h3 id="new-tests-for-api-functions-0-1-8">New tests for API functions<a class="anchor" aria-label="anchor" href="#new-tests-for-api-functions-0-1-8"></a></h3>
<ul><li>
<strong>Easier Troubleshooting in API-function</strong>: All API functions now support the <code>.dry_run</code> argument, allowing users to generate an <code>httr2</code>-request for easier debugging and inspection.</li>
<li>
<strong>API Function Tests:</strong> Implemented <code>httptest2</code>-based tests with mock responses for all API functions, covering both basic functionality and rate-limiting.</li>
</ul></div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Eduard BrÃ¼ll.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer></div>





  </body></html>

