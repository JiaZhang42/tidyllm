url: https://edubruell.github.io/tidyllm/
template:
  bootstrap: 5
  bootswatch: litera  
  assets:
    css: ["extra.scss"]
    
reference:
  - title: "LLM Message Handling"
    contents:
      - llm_message
      - df_llm_message
      - get_reply
      - get_reply_data
      - get_user_message
      - last_reply
      - last_reply_data
      - last_user_message
      - tidyllm_schema

  - title: "Core Chat-API Functions"
    contents:
      - openai
      - claude
      - groq
      - mistral
      - ollama
      - azure_openai
      - chatgpt # Deprecated, use openai instead
      
  - title: "Bacth Request API Functions"
    contents:
    - send_claude_batch
    - check_claude_batch
    - fetch_claude_batch
    - list_claude_batches
    - send_openai_batch
    - check_openai_batch
    - fetch_openai_batch
    - list_openai_batches

  - title: "Embedding API Functions"
    contents:
    - ollama_embedding
    - openai_embedding
    - mistral_embedding
    
  - title: "Other API Functions"
    contents:
    - groq_transcribe

  - title: "Ollama Functions"
    contents:
      - ollama_download_model
      - ollama_list_models

  - title: "Internals and Utility Functions"
    contents:
      - LLMMessage
      - perform_api_request
      - generate_callback_function
      - initialize_api_env
      - rate_limit_info
      - update_rate_limit
      - parse_duration_to_seconds
      - ratelimit_from_header

  - title: "PDF Processing"
    contents:
      - pdf_page_batch


